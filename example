You have a small OTP application that continuously syncs EVE market data for many regions, using supervision, GenServers, ETS, and Postgres. Here’s the architecture in plain terms.
Top-level application

    Marketmailer.Application is your entry point.

    On start, it:

        Starts the Ecto repo Marketmailer.Database (connection to Postgres).

        Starts a Registry for naming worker processes by region.

        Starts Marketmailer.RegionDynamicSupervisor (to manage region workers).

        Starts Marketmailer.RegionManager (to orchestrate which regions get workers).

So the supervision tree is:

    Application supervisor

        Repo (DB)

        Registry

        RegionDynamicSupervisor

        RegionManager

Region manager (orchestrator)

    Marketmailer.RegionManager is a GenServer that knows the list of region IDs (@regions).

    On init, it sends itself {:start_workers, @regions}.

    In handle_info/2, it:

        Takes [region | rest], starts a worker for region via the DynamicSupervisor.

        Schedules another message {:start_workers, rest} in 100 ms.

Effect: workers are started gradually (throttled), not all at once, until every region has its own worker process.
Region dynamic supervisor

    Marketmailer.RegionDynamicSupervisor is a DynamicSupervisor.

    It doesn’t have a static child list; instead it exposes start_child(region_id).

    For each region, start_child/1 creates a Marketmailer.RegionWorker with that region ID.

    If a RegionWorker crashes (depending on restart settings), the DynamicSupervisor handles restarting it.

This gives you one long-lived worker process per region, managed under OTP supervision.
Region worker (per-region poller)

    Marketmailer.RegionWorker is a GenServer whose job is:

        Periodically fetch market orders for its region from ESI.

        Use ETag + If-None-Match to avoid unnecessary data transfers.

        Upsert orders into Postgres.

        Decide when to fetch next, based on HTTP Expires (TTL).

Key flow:

    init/1:

        Stores the region_id in state, sends itself :work immediately.

    handle_info(:work, state):

        Calls fetch_region(region_id) which returns a delay (ms) until the next check.

        Schedules the next :work using Process.send_after/3 with delay + 2000 (buffer).

    fetch_region/1:

        Builds region URL.

        Calls fetch_page(url, region_id, 1).

        On success, returns TTL. On error, falls back to 60 seconds.

    fetch_page/3:

        Looks up ETag for this URL in ETS/DB.

        Sends HTTP request with optional If-None-Match.

        If status 304:

            No new data; compute TTL from headers and return.

        If status 200:

            Extract new ETag, save it (ETS + DB).

            Upsert all orders into DB.

            If this is page 1, spawn parallel tasks to fetch pages 2..N.

            Compute TTL and return.

So each region worker is an autonomous, repeating loop: fetch → decide next time → sleep → repeat.
HTTP TTL and date parsing

    calculate_ttl/1 reads the Expires header, parses it as an HTTP date, and computes ms until expiry.

    If the date is invalid or missing, it falls back to a default (5 minutes).

    If the computed diff is negative or tiny (clock skew, already expired), it uses at least 30 seconds.

That TTL feeds back into the worker’s scheduling logic, so each region polls at a cadence dictated by ESI.
ETag caching and ETS + DB

    Workers use the ETS table :market_etags to cache ETags by URL in memory.

    get_etag_with_fallback/1:

        First looks in ETS.

        If not found, checks the etags table in Postgres via Marketmailer.Database.get(Etag, url).

        On DB hit, it warms ETS and returns the ETag.

    save_etag/2:

        Writes to ETS.

        Upserts into the etags table with an Ecto changeset and on_conflict on url.

This gives you:

    Fast in-memory lookups during normal operation.

    Persistence across restarts via the DB.

You just need to ensure the ETS table is created once at startup.
Database schemas

    Market schema:

        Represents a market order record with fields like order_id, price, volume_total, etc.

        upsert_orders/3:

            Normalizes incoming JSON maps (string keys → atoms).

            Adds inserted_at and updated_at timestamps.

            Inserts in chunks (insert_all) with an on_conflict upsert keyed by order_id.

            Only updates a set of selected fields and updated_at, preserving original inserted_at.

    Etag schema:

        Primary key is url.

        Holds the current etag string plus timestamps.

        Used by the ETag caching logic as the persistent store.

Naming and introspection

    Registry is used to give each RegionWorker a stable, named identifier:

        Name pattern: {:via, Registry, {Marketmailer.Registry, {:region, region_id}}}.

        This allows you to find or send messages to a specific region worker by its region ID.

In short: the architecture is a supervised tree where each region has a dedicated worker GenServer, all managed by a DynamicSupervisor and orchestrated by a RegionManager, with ETag-based caching backed by ETS and Postgres to efficiently poll and upsert market orders over time.
